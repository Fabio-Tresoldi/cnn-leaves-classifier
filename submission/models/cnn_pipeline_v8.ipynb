{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "cnn_pipeline_v8.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRtl6hB-vs_U"
      },
      "source": [
        "# CNN Pipeline v8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsXz12ot7PBB"
      },
      "source": [
        "## Environment settings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PoKdpXXtab1"
      },
      "source": [
        "### Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVT6JS9FvzwC",
        "execution": {
          "iopub.status.busy": "2021-11-17T23:01:07.034968Z",
          "iopub.execute_input": "2021-11-17T23:01:07.035269Z",
          "iopub.status.idle": "2021-11-17T23:01:14.329382Z",
          "shell.execute_reply.started": "2021-11-17T23:01:07.035217Z",
          "shell.execute_reply": "2021-11-17T23:01:14.328435Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be6bac95-facb-48ca-b8bc-f350cba20300"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from PIL import Image, ImageFilter, ImageEnhance\n",
        "from numpy import asarray\n",
        "from sklearn.utils import shuffle\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from IPython.display import clear_output\n",
        "import math\n",
        "\n",
        "tfk = tf.keras\n",
        "tfkl = tf.keras.layers\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4Q-CAiNtnRP"
      },
      "source": [
        "### Random seed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJfQgW-bto8I",
        "execution": {
          "iopub.status.busy": "2021-11-17T23:01:19.047964Z",
          "iopub.execute_input": "2021-11-17T23:01:19.048470Z",
          "iopub.status.idle": "2021-11-17T23:01:19.054041Z",
          "shell.execute_reply.started": "2021-11-17T23:01:19.048428Z",
          "shell.execute_reply": "2021-11-17T23:01:19.052951Z"
        },
        "trusted": true
      },
      "source": [
        "# Random seed for reproducibility\n",
        "seed = 42\n",
        "\n",
        "random.seed(seed)\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "tf.compat.v1.set_random_seed(seed)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ix1cVRCF7Svm"
      },
      "source": [
        "## Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Znsy7xWLwVJN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e52af7f1-fb17-470c-e064-3c287f23c400"
      },
      "source": [
        "# google drive plug-in\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4NxuSzOwXCT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10c1f961-d97c-44cd-e400-527d106fcc91"
      },
      "source": [
        "# directory\n",
        "%cd /gdrive/MyDrive/notebooks/an2dl_homeworks/training_validation_testing/mirko"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/gdrive/MyDrive/notebooks/an2dl_homeworks/training_validation_testing/mirko\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fN5i13swxHia",
        "execution": {
          "iopub.status.busy": "2021-11-17T23:01:24.559295Z",
          "iopub.execute_input": "2021-11-17T23:01:24.559939Z",
          "iopub.status.idle": "2021-11-17T23:01:24.565596Z",
          "shell.execute_reply.started": "2021-11-17T23:01:24.559883Z",
          "shell.execute_reply": "2021-11-17T23:01:24.564669Z"
        },
        "trusted": true
      },
      "source": [
        "# paths\n",
        "root_path = '../../training_validation_testing/mirko/'#'/kaggle/input/leaves-2/leaves_train_val/'#\n",
        "training_dir = os.path.join(root_path, 'training')\n",
        "validation_dir = os.path.join(root_path, 'validation')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rvwrd5Zz8rmC"
      },
      "source": [
        "## Data Pre-Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DDOJSRiu2fU"
      },
      "source": [
        "### Generators"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbggF9aRubWs"
      },
      "source": [
        "#### Training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exXEJNwnuwU1",
        "execution": {
          "iopub.status.busy": "2021-11-17T23:01:45.988551Z",
          "iopub.execute_input": "2021-11-17T23:01:45.989047Z",
          "iopub.status.idle": "2021-11-17T23:01:45.993640Z",
          "shell.execute_reply.started": "2021-11-17T23:01:45.989013Z",
          "shell.execute_reply": "2021-11-17T23:01:45.992806Z"
        },
        "trusted": true
      },
      "source": [
        "# ------------------------------------------------------------------------------\n",
        "# FIXED TRAINING ---------------------------------------------------------------\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "# MEAN CENTER SHIFT\n",
        "z_score_mean = [[[51.14068, 68.74184, 40.975986]]]\n",
        "\n",
        "# STD NORMALIZATION\n",
        "z_score_std = [[[81.23509, 104.63732, 66.81536]]]\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "# constructor\n",
        "train_data_gen = ImageDataGenerator(\n",
        "    # data augmentation\n",
        "    rotation_range=30,\n",
        "    height_shift_range=50,\n",
        "    width_shift_range=50,\n",
        "    zoom_range=0.3,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    brightness_range=[0.5,1.5],\n",
        "    fill_mode='reflect',\n",
        "\n",
        "    # z-score\n",
        "    featurewise_center=False, # mean center shift\n",
        "    featurewise_std_normalization=False # std normalization\n",
        ")\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "# generator\n",
        "train_gen = train_data_gen.flow_from_directory(\n",
        "    directory=training_dir,\n",
        "    target_size=(256,256),\n",
        "    color_mode='rgb',\n",
        "    classes=None,\n",
        "    class_mode='categorical',\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    seed=seed\n",
        ")\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "# custom\n",
        "def train_gen_z_score():\n",
        "  # yielding batch's samples at run time when called from the generator\n",
        "  for (x, y) in train_gen:\n",
        "    x = (x - z_score_mean) / z_score_std\n",
        "    yield (x, y)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3L1f-wyeuG9I"
      },
      "source": [
        "#### New Training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-17T22:47:26.670923Z",
          "iopub.execute_input": "2021-11-17T22:47:26.671326Z",
          "iopub.status.idle": "2021-11-17T22:51:57.348585Z",
          "shell.execute_reply.started": "2021-11-17T22:47:26.671281Z",
          "shell.execute_reply": "2021-11-17T22:51:57.347761Z"
        },
        "trusted": true,
        "id": "4qRE3oO4MSus"
      },
      "source": [
        "# ------------------------------------------------------------------------------\n",
        "# NEW TRAINING -----------------------------------------------------------------\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "# constructor\n",
        "train_data_gen = ImageDataGenerator(\n",
        "    # data augmentation\n",
        "    rotation_range=30,\n",
        "    height_shift_range=50,\n",
        "    width_shift_range=50,\n",
        "    zoom_range=0.3,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    brightness_range=[0.5,1.5],\n",
        "    fill_mode='reflect',\n",
        "\n",
        "    # z-score\n",
        "    featurewise_center=False, # mean center shift\n",
        "    featurewise_std_normalization=False # std normalization\n",
        ")\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "# generator\n",
        "train_gen = train_data_gen.flow_from_directory(\n",
        "    directory= root_path + 'training',\n",
        "    target_size=(256,256),\n",
        "    color_mode='rgb',\n",
        "    classes=None,\n",
        "    class_mode='categorical',\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    seed=seed\n",
        ")\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "# callable generator method\n",
        "def CallableGenerator():\n",
        "  # yielding batch's samples at run time when called from the generator\n",
        "  for (x,y) in train_gen:\n",
        "    yield (x,y)\n",
        "\n",
        "# TENSOR-BATCHED DATASET (from generator)\n",
        "batched_dataset = tf.data.Dataset.from_generator(\n",
        "    # above method for run time\n",
        "    CallableGenerator,\n",
        "\n",
        "    # tensor fields types\n",
        "    output_types=(tf.float32, tf.float32)\n",
        ") \n",
        "\n",
        "# TENSOR-UNBATCHED DATASET (from batched-dataset)\n",
        "mean = tf.Variable(\n",
        "    # RGB dimension        \n",
        "    np.zeros((3), dtype=np.float32)\n",
        ")\n",
        "mean_2 = tf.Variable(\n",
        "    # RGB dimension        \n",
        "    np.zeros((3), dtype=np.float32)\n",
        ")\n",
        "std = tf.Variable(\n",
        "    # RGB dimension        \n",
        "    np.zeros((3), dtype=np.float32)\n",
        ")\n",
        "\n",
        "# visualization variables\n",
        "i = 0 # counter\n",
        "tot_epoch = math.ceil(train_gen.samples / 32) # total epoch\n",
        "\n",
        "# ONE EPOCH LOADING\n",
        "for (x, _) in iter(batched_dataset):\n",
        "  # update visualization\n",
        "  clear_output(wait=True)\n",
        "  i += 1\n",
        "  print(\"Epoch (1/1) - Batch : \" + str(i) + \"/\" + str(tot_epoch))\n",
        "\n",
        "  # incremental mean\n",
        "  mean.assign_add(\n",
        "      tf.math.divide(\n",
        "        tf.math.reduce_sum(x, axis=[0, 1, 2]),\n",
        "        256 * 256 * train_gen.samples\n",
        "      )\n",
        "  )\n",
        "\n",
        "  # incremental mean squared\n",
        "  mean_2.assign_add(\n",
        "      tf.math.divide(\n",
        "        tf.math.reduce_sum(tf.math.square(x), axis=[0, 1, 2]),\n",
        "        256 * 256 * train_gen.samples\n",
        "      )\n",
        "  )\n",
        "    \n",
        "  # end condition, otherwise unlimited\n",
        "  if i > tot_epoch:\n",
        "      break\n",
        "\n",
        "# standard deviation\n",
        "std = tf.math.sqrt(\n",
        "    tf.math.subtract(mean_2, mean)\n",
        ")\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "# reshape\n",
        "z_score_mean = tf.reshape(mean, (1, 1, 3))\n",
        "z_score_std = tf.reshape(std, (1, 1, 3))\n",
        "\n",
        "# visualization\n",
        "print('training set mean :', z_score_mean)\n",
        "print('training set std :', z_score_std)\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "# generator\n",
        "train_gen = train_data_gen.flow_from_directory(\n",
        "    directory=training_dir,\n",
        "    target_size=(256,256),\n",
        "    color_mode='rgb',\n",
        "    classes=None,\n",
        "    class_mode='categorical',\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    seed=seed\n",
        ")\n",
        "\n",
        "# custom\n",
        "def train_gen_z_score():\n",
        "  # yielding batch's samples at run time when called from the generator\n",
        "  for (x, y) in train_gen:\n",
        "    x = (x - z_score_mean) / z_score_std\n",
        "    yield (x, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fek6lP2Tqv4e"
      },
      "source": [
        "#### Validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5tB0i1crCoB",
        "execution": {
          "iopub.status.busy": "2021-11-17T23:10:56.662571Z",
          "iopub.execute_input": "2021-11-17T23:10:56.663456Z",
          "iopub.status.idle": "2021-11-17T23:10:56.891061Z",
          "shell.execute_reply.started": "2021-11-17T23:10:56.663415Z",
          "shell.execute_reply": "2021-11-17T23:10:56.889997Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45369e7c-a01d-4da2-8bca-fc3ca2f804c6"
      },
      "source": [
        "# VALIDATION -------------------------------------------------------------------\n",
        "\n",
        "# constructor\n",
        "valid_data_gen = ImageDataGenerator(\n",
        "    # z-score\n",
        "    featurewise_center=False, # mean center shift\n",
        "    featurewise_std_normalization=False # std normalization\n",
        ")\n",
        "\n",
        "# generator\n",
        "valid_gen = valid_data_gen.flow_from_directory(\n",
        "    directory=validation_dir,\n",
        "    target_size=(256,256),\n",
        "    color_mode='rgb',\n",
        "    classes=None,\n",
        "    class_mode='categorical',\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    seed=seed\n",
        ")\n",
        "\n",
        "def valid_gen_z_score():\n",
        "  # yielding batch's samples at run time when called from the generator\n",
        "  while True:\n",
        "    for (x, y) in train_gen:\n",
        "      x = (x - z_score_mean) / z_score_std\n",
        "      yield (x, y)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3547 images belonging to 14 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Nuy88eiyZVA"
      },
      "source": [
        "## Model Design"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72TxDCRj88ro",
        "execution": {
          "iopub.status.busy": "2021-11-17T23:02:37.104465Z",
          "iopub.execute_input": "2021-11-17T23:02:37.105039Z",
          "iopub.status.idle": "2021-11-17T23:02:37.109297Z",
          "shell.execute_reply.started": "2021-11-17T23:02:37.105001Z",
          "shell.execute_reply": "2021-11-17T23:02:37.108301Z"
        },
        "trusted": true
      },
      "source": [
        "# labels\n",
        "labels = ['Apple','Blueberry','Cherry','Corn','Grape','Orange','Peach','Pepper','Potato','Raspberry','Soybean','Squash','Strawberry','Tomato']"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTORqKWWzu-0",
        "execution": {
          "iopub.status.busy": "2021-11-17T23:02:40.106160Z",
          "iopub.execute_input": "2021-11-17T23:02:40.107055Z",
          "iopub.status.idle": "2021-11-17T23:02:40.112391Z",
          "shell.execute_reply.started": "2021-11-17T23:02:40.106997Z",
          "shell.execute_reply": "2021-11-17T23:02:40.111579Z"
        },
        "trusted": true
      },
      "source": [
        "# Model hyperparameters\n",
        "input_shape = (256, 256, 3)\n",
        "epochs = 100\n",
        "batch_size = 32\n",
        "n_classes = len(labels)\n",
        "weight_decay = 1e-5\n",
        "model_name = \"cnn_v1\""
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUYcW3XBycYU",
        "execution": {
          "iopub.status.busy": "2021-11-17T23:02:43.039583Z",
          "iopub.execute_input": "2021-11-17T23:02:43.039854Z",
          "iopub.status.idle": "2021-11-17T23:02:43.071405Z",
          "shell.execute_reply.started": "2021-11-17T23:02:43.039824Z",
          "shell.execute_reply": "2021-11-17T23:02:43.070324Z"
        },
        "trusted": true
      },
      "source": [
        "# Model skeleton\n",
        "def mirknet(input_shape):\n",
        "    # (0) input\n",
        "    input_layer = tfkl.Input(shape=input_shape, name='Input')\n",
        "\n",
        "    # (1) \n",
        "    conv1 = tfkl.Conv2D(\n",
        "        filters=16,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed),\n",
        "        kernel_regularizer=tf.keras.regularizers.l2(weight_decay)\n",
        "    )(input_layer)\n",
        "    drop1 = tfkl.Dropout(0.5, seed=seed)(conv1)\n",
        "    relu1 = tf.keras.layers.ReLU()(drop1)\n",
        "    pool1 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(relu1)\n",
        "\n",
        "    # (2)\n",
        "    conv2 = tfkl.Conv2D(\n",
        "        filters=32,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool1)\n",
        "    drop2 = tfkl.Dropout(0.6, seed=seed)(conv2)\n",
        "    relu2 = tf.keras.layers.ReLU()(drop2)\n",
        "    pool2 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(relu2)\n",
        "\n",
        "    # (3)\n",
        "    conv3 = tfkl.Conv2D(\n",
        "        filters=64,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool2)\n",
        "    drop3 = tfkl.Dropout(0.7, seed=seed)(conv3)\n",
        "    relu3 = tf.keras.layers.ReLU()(drop3)\n",
        "    pool3 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(relu3)\n",
        "\n",
        "    # (4) \n",
        "    conv4 = tfkl.Conv2D(\n",
        "        filters=128,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool3)\n",
        "    drop4 = tfkl.Dropout(0.8, seed=seed)(conv4)\n",
        "    relu4 = tf.keras.layers.ReLU()(drop4)\n",
        "    pool4 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(relu4)\n",
        "\n",
        "    # (5)\n",
        "    conv5 = tfkl.Conv2D(\n",
        "        filters=256,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool4)\n",
        "    drop5 = tfkl.Dropout(0.9, seed=seed)(conv5)\n",
        "    relu5 = tf.keras.layers.ReLU()(drop5)\n",
        "    pool5 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(relu5)\n",
        "\n",
        "    # (5) \n",
        "    conv6 = tfkl.Conv2D(\n",
        "        filters=512,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool5)\n",
        "    batch_norm6 = tfkl.BatchNormalization()(conv6)\n",
        "    relu6 = tf.keras.layers.ReLU()(batch_norm6)\n",
        "    gap6 = tfkl.GlobalAveragePooling2D()(relu6)\n",
        "\n",
        "    # (6)\n",
        "    flattening_layer = tfkl.Flatten(name='Flatten')(gap6)\n",
        "\n",
        "    flattening_layer = tfkl.Dropout(0.5, seed=seed)(flattening_layer)\n",
        "    classifier_layer = tfkl.Dense(units=512,\n",
        "                                  name='Classifier_1',\n",
        "                                  kernel_initializer=tfk.initializers.GlorotUniform(seed),\n",
        "                                  kernel_regularizer=tf.keras.regularizers.l2(weight_decay),\n",
        "                                  activation='relu')(flattening_layer)\n",
        "\n",
        "    flattening_layer = tfkl.Dropout(0.6, seed=seed)(classifier_layer)\n",
        "    classifier_layer = tfkl.Dense(units=256,\n",
        "                                  name='Classifier_2',\n",
        "                                  kernel_initializer=tfk.initializers.GlorotUniform(seed),\n",
        "                                  activation='relu')(flattening_layer)\n",
        "\n",
        "    flattening_layer = tfkl.Dropout(0.7, seed=seed)(classifier_layer)\n",
        "    classifier_layer = tfkl.Dense(units=128,\n",
        "                                  name='Classifier_3',\n",
        "                                  kernel_initializer=tfk.initializers.GlorotUniform(seed),\n",
        "                                  activation='relu')(flattening_layer)\n",
        "\n",
        "    flattening_layer = tfkl.Dropout(0.8, seed=seed)(classifier_layer)\n",
        "    classifier_layer = tfkl.Dense(units=64,\n",
        "                                  name='Classifier_4',\n",
        "                                  kernel_initializer=tfk.initializers.GlorotUniform(seed),\n",
        "                                  activation='relu')(flattening_layer)\n",
        "\n",
        "    flattening_layer = tfkl.Dropout(0.9, seed=seed)(classifier_layer)\n",
        "    classifier_layer = tfkl.Dense(units=32,\n",
        "                                  name='Classifier_5',\n",
        "                                  kernel_initializer=tfk.initializers.GlorotUniform(seed),\n",
        "                                  activation='relu')(flattening_layer)\n",
        "    batch_norm = tfkl.BatchNormalization()(classifier_layer)\n",
        "\n",
        "    output_layer = tfkl.Dense(units=n_classes, activation='softmax', \n",
        "                              kernel_initializer=tfk.initializers.GlorotUniform(seed), \n",
        "                              name='Output')(batch_norm)\n",
        "\n",
        "    # Model connection\n",
        "    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='model')\n",
        "\n",
        "    # Model Compilation\n",
        "    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics='accuracy')\n",
        "\n",
        "    # Return the model\n",
        "    return model"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWxEMZ4Tzn5F",
        "execution": {
          "iopub.status.busy": "2021-11-17T23:02:47.758387Z",
          "iopub.execute_input": "2021-11-17T23:02:47.759266Z",
          "iopub.status.idle": "2021-11-17T23:02:48.136885Z",
          "shell.execute_reply.started": "2021-11-17T23:02:47.759173Z",
          "shell.execute_reply": "2021-11-17T23:02:48.135795Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3139a8d-30f3-43c5-c23c-bf8f3530ea8b"
      },
      "source": [
        "# Build model\n",
        "model = mirknet(input_shape)\n",
        "model.summary()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Input (InputLayer)          [(None, 256, 256, 3)]     0         \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 256, 256, 16)      448       \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 256, 256, 16)      0         \n",
            "                                                                 \n",
            " re_lu_6 (ReLU)              (None, 256, 256, 16)      0         \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 128, 128, 16)     0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 128, 128, 32)      4640      \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 128, 128, 32)      0         \n",
            "                                                                 \n",
            " re_lu_7 (ReLU)              (None, 128, 128, 32)      0         \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 64, 64, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 64, 64, 64)        18496     \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 64, 64, 64)        0         \n",
            "                                                                 \n",
            " re_lu_8 (ReLU)              (None, 64, 64, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 32, 32, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 32, 32, 128)       73856     \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 32, 32, 128)       0         \n",
            "                                                                 \n",
            " re_lu_9 (ReLU)              (None, 32, 32, 128)       0         \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPooling  (None, 16, 16, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 16, 16, 256)       295168    \n",
            "                                                                 \n",
            " dropout_14 (Dropout)        (None, 16, 16, 256)       0         \n",
            "                                                                 \n",
            " re_lu_10 (ReLU)             (None, 16, 16, 256)       0         \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPooling  (None, 8, 8, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 8, 8, 512)         1180160   \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 8, 8, 512)        2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " re_lu_11 (ReLU)             (None, 8, 8, 512)         0         \n",
            "                                                                 \n",
            " global_average_pooling2d_1   (None, 512)              0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " Flatten (Flatten)           (None, 512)               0         \n",
            "                                                                 \n",
            " dropout_15 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " Classifier_1 (Dense)        (None, 512)               262656    \n",
            "                                                                 \n",
            " dropout_16 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " Classifier_2 (Dense)        (None, 256)               131328    \n",
            "                                                                 \n",
            " dropout_17 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " Classifier_3 (Dense)        (None, 128)               32896     \n",
            "                                                                 \n",
            " dropout_18 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " Classifier_4 (Dense)        (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_19 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " Classifier_5 (Dense)        (None, 32)                2080      \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 32)               128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " Output (Dense)              (None, 14)                462       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,012,622\n",
            "Trainable params: 2,011,534\n",
            "Non-trainable params: 1,088\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hBriTOK51E7",
        "execution": {
          "iopub.status.busy": "2021-11-17T23:03:10.104005Z",
          "iopub.execute_input": "2021-11-17T23:03:10.104541Z",
          "iopub.status.idle": "2021-11-17T23:03:10.113980Z",
          "shell.execute_reply.started": "2021-11-17T23:03:10.104499Z",
          "shell.execute_reply": "2021-11-17T23:03:10.113104Z"
        },
        "trusted": true
      },
      "source": [
        "# Utility function to create folders and callbacks for training\n",
        "from datetime import datetime\n",
        "\n",
        "def create_folders_and_callbacks(model_name):\n",
        "\n",
        "  exps_dir = os.path.join('/kaggle/working/models')#root_path+'/new_model_gap')\n",
        "  if not os.path.exists(exps_dir):\n",
        "      os.makedirs(exps_dir)\n",
        "\n",
        "  now = datetime.now().strftime('%b%d_%H-%M-%S')\n",
        "\n",
        "  exp_dir = os.path.join(exps_dir, model_name + '_' + str(now))\n",
        "  if not os.path.exists(exp_dir):\n",
        "      os.makedirs(exp_dir)\n",
        "      \n",
        "  callbacks = []\n",
        "\n",
        "  # Model checkpoint\n",
        "  # ----------------\n",
        "  ckpt_dir = os.path.join(exp_dir, 'ckpts')\n",
        "  if not os.path.exists(ckpt_dir):\n",
        "      os.makedirs(ckpt_dir)\n",
        "\n",
        "  ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(ckpt_dir, 'cp.ckpt'), \n",
        "                                                     save_weights_only=False, # True to save only weights\n",
        "                                                     save_best_only=False) # True to save only the best epoch \n",
        "  callbacks.append(ckpt_callback)\n",
        "\n",
        "  # Early Stopping\n",
        "  # --------------\n",
        "  es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "  callbacks.append(es_callback)\n",
        "\n",
        "  return callbacks"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QR-oE0mC6vrh",
        "execution": {
          "iopub.status.busy": "2021-11-17T23:11:10.039589Z",
          "iopub.execute_input": "2021-11-17T23:11:10.039901Z",
          "iopub.status.idle": "2021-11-17T23:11:10.076322Z",
          "shell.execute_reply.started": "2021-11-17T23:11:10.039870Z",
          "shell.execute_reply": "2021-11-17T23:11:10.075013Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "outputId": "e93751a0-42a5-4f3e-d23c-538159f0f2e9"
      },
      "source": [
        "# Create folders and callbacks and fit\n",
        "callbacks = create_folders_and_callbacks(model_name='CNN_full')\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    x = train_gen_z_score(),\n",
        "    batch_size = batch_size,\n",
        "    epochs = epochs,\n",
        "    validation_data = valid_gen_z_score(),\n",
        "    callbacks=[callbacks],\n",
        "    steps_per_epoch = train_gen.samples // batch_size\n",
        ").history"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "  7/332 [..............................] - ETA: 21:34 - loss: 3.1618 - accuracy: 0.0670"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-6621df0df2a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_gen_z_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m ).history\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3130\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3131\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3133\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1960\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1962\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    601\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    604\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HK13X-hm6zxR"
      },
      "source": [
        "# Save best epoch model\n",
        "model.save(\"models/CNN_full_best_\" + str(datetime.now().strftime('%b%d_%H-%M-%S')))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}