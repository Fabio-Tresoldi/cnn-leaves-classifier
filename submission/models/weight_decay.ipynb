{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weight Decay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "tfk = tf.keras\n",
    "tfkl = tf.keras.layers\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random seed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random seed for reproducibility\n",
    "seed = 42\n",
    "\n",
    "random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "tf.compat.v1.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-Processing\n",
    "We extract the data by collecting images with their own target label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Apple','Blueberry','Cherry','Corn','Grape','Orange','Peach','Pepper','Potato','Raspberry','Soybean','Squash','Strawberry','Tomato']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10629 images belonging to 14 classes.\n",
      "Found 3547 images belonging to 14 classes.\n",
      "Found 3552 images belonging to 14 classes.\n"
     ]
    }
   ],
   "source": [
    "# root path\n",
    "path = '../../training_validation_testing/mirko/'\n",
    "\n",
    "# Create an instance of ImageDataGenerator for training, validation, and test sets\n",
    "train_data_gen = ImageDataGenerator(rescale=1/255.)\n",
    "valid_data_gen = ImageDataGenerator(rescale=1/255.)\n",
    "test_data_gen = ImageDataGenerator(rescale=1/255.)\n",
    "\n",
    "# Obtain a data generator with the 'ImageDataGenerator.flow_from_directory' method\n",
    "train_gen = train_data_gen.flow_from_directory(directory=path+'training',\n",
    "                                             target_size=(256,256),\n",
    "                                             color_mode='rgb',\n",
    "                                             classes=None, # can be set to labels\n",
    "                                             class_mode='categorical',\n",
    "                                             batch_size=8,\n",
    "                                             shuffle=True,\n",
    "                                             seed=seed)\n",
    "\n",
    "# Obtain a data generator with the 'ImageDataGenerator.flow_from_directory' method\n",
    "valid_gen = valid_data_gen.flow_from_directory(directory=path+'validation',\n",
    "                                             target_size=(256,256),\n",
    "                                             color_mode='rgb',\n",
    "                                             classes=None, # can be set to labels\n",
    "                                             class_mode='categorical',\n",
    "                                             batch_size=8,\n",
    "                                             shuffle=True,\n",
    "                                             seed=seed)\n",
    "\n",
    "# Obtain a data generator with the 'ImageDataGenerator.flow_from_directory' method\n",
    "test_gen = test_data_gen.flow_from_directory(directory=path+'testing',\n",
    "                                             target_size=(256,256),\n",
    "                                             color_mode='rgb',\n",
    "                                             classes=None, # can be set to labels\n",
    "                                             class_mode='categorical',\n",
    "                                             batch_size=8,\n",
    "                                             shuffle=True,\n",
    "                                             seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (256, 256, 3)\n",
    "epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model used for the exercise:\n",
    "# (Conv + ReLU + MaxPool) x 5 + FC x 2\n",
    "def build_model(input_shape):\n",
    "\n",
    "    # Build the neural network layer by layer\n",
    "    input_layer = tfkl.Input(shape=input_shape, name='Input')\n",
    "\n",
    "    conv1 = tfkl.Conv2D(\n",
    "        filters=16,\n",
    "        kernel_size=(3, 3),\n",
    "        strides = (1, 1),\n",
    "        padding = 'same',\n",
    "        activation = 'relu',\n",
    "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
    "    )(input_layer)\n",
    "    pool1 = tfkl.MaxPooling2D(\n",
    "        pool_size = (2, 2)\n",
    "    )(conv1)\n",
    "\n",
    "    conv2 = tfkl.Conv2D(\n",
    "        filters=32,\n",
    "        kernel_size=(3, 3),\n",
    "        strides = (1, 1),\n",
    "        padding = 'same',\n",
    "        activation = 'relu',\n",
    "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
    "    )(pool1)\n",
    "    pool2 = tfkl.MaxPooling2D(\n",
    "        pool_size = (2, 2)\n",
    "    )(conv2)\n",
    "\n",
    "    conv3 = tfkl.Conv2D(\n",
    "        filters=64,\n",
    "        kernel_size=(3, 3),\n",
    "        strides = (1, 1),\n",
    "        padding = 'same',\n",
    "        activation = 'relu',\n",
    "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
    "    )(pool2)\n",
    "    pool3 = tfkl.MaxPooling2D(\n",
    "        pool_size = (2, 2)\n",
    "    )(conv3)\n",
    "\n",
    "    conv4 = tfkl.Conv2D(\n",
    "        filters=128,\n",
    "        kernel_size=(3, 3),\n",
    "        strides = (1, 1),\n",
    "        padding = 'same',\n",
    "        activation = 'relu',\n",
    "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
    "    )(pool3)\n",
    "    pool4 = tfkl.MaxPooling2D(\n",
    "        pool_size = (2, 2)\n",
    "    )(conv4)\n",
    "\n",
    "    conv5 = tfkl.Conv2D(\n",
    "        filters=256,\n",
    "        kernel_size=(3, 3),\n",
    "        strides = (1, 1),\n",
    "        padding = 'same',\n",
    "        activation = 'relu',\n",
    "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
    "    )(pool4)\n",
    "    pool5 = tfkl.MaxPooling2D(\n",
    "        pool_size = (2, 2)\n",
    "    )(conv5)\n",
    "\n",
    "    flattening_layer = tfkl.Flatten(name='Flatten')(pool5)\n",
    "    flattening_layer = tfkl.Dropout(0.3, seed=seed)(flattening_layer)\n",
    "    classifier_layer = tfkl.Dense(units=512, name='Classifier', kernel_initializer=tfk.initializers.GlorotUniform(seed), activation='relu')(flattening_layer)\n",
    "    classifier_layer = tfkl.Dropout(0.3, seed=seed)(classifier_layer)\n",
    "    output_layer = tfkl.Dense(units=21, activation='softmax', kernel_initializer=tfk.initializers.GlorotUniform(seed), name='Output')(classifier_layer)\n",
    "\n",
    "    # Connect input and output through the Model class\n",
    "    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='model')\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics='accuracy')\n",
    "\n",
    "    # Return the model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-14 15:56:12.967923: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (InputLayer)          [(None, 256, 256, 3)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 256, 256, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 128, 128, 16)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 128, 128, 32)      4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 64, 64, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 64, 64, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 32, 32, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 32, 32, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 16, 16, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 16, 16, 256)       295168    \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 8, 8, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " Flatten (Flatten)           (None, 16384)             0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 16384)             0         \n",
      "                                                                 \n",
      " Classifier (Dense)          (None, 512)               8389120   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " Output (Dense)              (None, 21)                10773     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,792,501\n",
      "Trainable params: 8,792,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(input_shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    x = train_gen,\n",
    "    epochs = epochs,\n",
    "    validation_data = valid_gen\n",
    ").history"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d5d63078528779411384a0109f22a688b37078cd4f03a8068939f652224ae60f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
