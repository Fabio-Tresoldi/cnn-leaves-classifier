{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Import Libraries","metadata":{"id":"7FUSNH_5Cmk-"}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport tensorflow as tf\nimport random\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\ntfk = tf.keras\ntfkl = tf.keras.layers\nprint(tf.__version__)","metadata":{"id":"Kad8mvnp85ML","outputId":"f719999b-f7b2-4558-d428-5c73b729c366","execution":{"iopub.status.busy":"2021-11-16T07:46:44.632266Z","iopub.execute_input":"2021-11-16T07:46:44.632605Z","iopub.status.idle":"2021-11-16T07:46:49.564853Z","shell.execute_reply.started":"2021-11-16T07:46:44.632512Z","shell.execute_reply":"2021-11-16T07:46:49.563286Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"### Set seed for reproducibility","metadata":{"id":"UXVTscKNDD6E"}},{"cell_type":"code","source":"# Random seed for reproducibility\nseed = 42\n\nrandom.seed(seed)\nos.environ['PYTHONHASHSEED'] = str(seed)\nnp.random.seed(seed)\ntf.random.set_seed(seed)\ntf.compat.v1.set_random_seed(seed)","metadata":{"id":"fC8b_ryv_5B2","execution":{"iopub.status.busy":"2021-11-16T07:47:46.856448Z","iopub.execute_input":"2021-11-16T07:47:46.856729Z","iopub.status.idle":"2021-11-16T07:47:46.861116Z","shell.execute_reply.started":"2021-11-16T07:47:46.856699Z","shell.execute_reply":"2021-11-16T07:47:46.860466Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"### Leaf Dataset","metadata":{"id":"1SzGSv5XDQdJ"}},{"cell_type":"code","source":"labels = ['Apple','Blueberry','Cherry','Corn','Grape','Orange','Peach','Pepper','Potato','Raspberry','Soybean','Squash','Strawberry','Tomato']","metadata":{"id":"k6tofdD7RNPd","execution":{"iopub.status.busy":"2021-11-16T07:47:49.336643Z","iopub.execute_input":"2021-11-16T07:47:49.337412Z","iopub.status.idle":"2021-11-16T07:47:49.341927Z","shell.execute_reply.started":"2021-11-16T07:47:49.337357Z","shell.execute_reply":"2021-11-16T07:47:49.341184Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"### Data Preprocessing\n\nDone in the other notebook","metadata":{"id":"qE0OYjwDUHeO"}},{"cell_type":"markdown","source":"### Data Loader","metadata":{"id":"g2ZxSFgNDcxb"}},{"cell_type":"code","source":"sub_dataset_dir = '/kaggle/input/leaves/leaves/'\ntraining_dir = os.path.join(sub_dataset_dir, 'training')\nvalidation_dir = os.path.join(sub_dataset_dir, 'validation')\ntest_dir = os.path.join(sub_dataset_dir, 'testing')","metadata":{"id":"57gAUPJ5CZeN","execution":{"iopub.status.busy":"2021-11-16T07:47:59.102461Z","iopub.execute_input":"2021-11-16T07:47:59.102733Z","iopub.status.idle":"2021-11-16T07:47:59.108046Z","shell.execute_reply.started":"2021-11-16T07:47:59.102704Z","shell.execute_reply":"2021-11-16T07:47:59.107218Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Images are divided into folders, one for each class. \n# If the images are organized in such a way, we can exploit the \n# ImageDataGenerator to read them from disk.\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Create an instance of ImageDataGenerator for training, validation, and test sets\n# Create an instance of ImageDataGenerator with Data Augmentation\ntrain_data_gen = ImageDataGenerator(#preprocessing_function=transformation,\n                                    rotation_range=30,\n                                    height_shift_range=50,\n                                    width_shift_range=50,\n                                    zoom_range=0.3,\n                                    horizontal_flip=True,\n                                    vertical_flip=True,\n                                    fill_mode='reflect', #)\n                                    rescale=1/255.) # rescale value is multiplied to the image\n\nvalid_data_gen = ImageDataGenerator(rescale=1/255.)#,\n                                    #preprocessing_function=transformation)\n\ntest_data_gen = ImageDataGenerator(rescale=1/255.)#,\n                                    #preprocessing_function=transformation)\n\n\n# Obtain a data generator with the 'ImageDataGenerator.flow_from_directory' method\ntrain_gen = train_data_gen.flow_from_directory(directory=training_dir,\n                                               target_size=(256,256),\n                                               color_mode='rgb',\n                                               classes=None, # can be set to labels\n                                               class_mode='categorical',\n                                               batch_size=8,\n                                               shuffle=True,\n                                               seed=seed)\n\nvalid_gen = train_data_gen.flow_from_directory(directory=validation_dir,\n                                               target_size=(256,256),\n                                               color_mode='rgb',\n                                               classes=None, # can be set to labels\n                                               class_mode='categorical',\n                                               batch_size=8,\n                                               shuffle=False,\n                                               seed=seed)\n\ntest_gen = train_data_gen.flow_from_directory(directory=test_dir,\n                                              target_size=(256,256),\n                                              color_mode='rgb',\n                                              classes=None, # can be set to labels\n                                              class_mode='categorical',\n                                              batch_size=8,\n                                              shuffle=False,\n                                              seed=seed)","metadata":{"id":"llN2rKFVDj66","outputId":"8a3fa12e-0acd-4afc-d4cc-fcd183439ce1","execution":{"iopub.status.busy":"2021-11-16T07:48:02.668965Z","iopub.execute_input":"2021-11-16T07:48:02.669223Z","iopub.status.idle":"2021-11-16T07:48:08.223253Z","shell.execute_reply.started":"2021-11-16T07:48:02.669194Z","shell.execute_reply":"2021-11-16T07:48:08.222529Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"### Model Metadata","metadata":{"id":"OYVCeITzJGSv"}},{"cell_type":"code","source":"# Model configuration\ninput_shape = (256, 256, 3)\nepochs = 100\nbatch_size = 64\nn_classes = 14\nweight_decay = 1e-5\nmodel_name = \"CNN_gap_64_rgb\"","metadata":{"id":"wxDSukBQJFZa","execution":{"iopub.status.busy":"2021-11-16T07:48:15.333793Z","iopub.execute_input":"2021-11-16T07:48:15.334052Z","iopub.status.idle":"2021-11-16T07:48:15.340525Z","shell.execute_reply.started":"2021-11-16T07:48:15.334024Z","shell.execute_reply":"2021-11-16T07:48:15.339715Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"### CNN Model","metadata":{"id":"TEjoTVrlJMN-"}},{"cell_type":"markdown","source":"* Batch Norm\n* Early Stopping\n* Batch\n* Increasing Dropout\n* Weight Decay\n* Weight Initialization\n* Data Augmentation","metadata":{"id":"4mDSltclL3Xn"}},{"cell_type":"code","source":"# Model used for the exercise:\n# (Conv + ReLU + MaxPool) x 4 + (Conv + ReLU + GlobalPooling) x 1 + FC x 2\ndef build_model(input_shape):\n\n    # Build the neural network layer by layer\n    input_layer = tfkl.Input(shape=input_shape, name='Input')\n\n    conv1 = tfkl.Conv2D(\n        filters=16,\n        kernel_size=(3, 3),\n        strides = (1, 1),\n        padding = 'same',\n        activation = 'relu',\n        kernel_initializer = tfk.initializers.GlorotUniform(seed),\n        kernel_regularizer=tf.keras.regularizers.l2(weight_decay)\n    )(input_layer)\n    batch_norm1 = tfkl.BatchNormalization()(conv1)\n    pool1 = tfkl.MaxPooling2D(\n        pool_size = (2, 2)\n    )(batch_norm1)\n\n    conv2 = tfkl.Conv2D(\n        filters=32,\n        kernel_size=(3, 3),\n        strides = (1, 1),\n        padding = 'same',\n        activation = 'relu',\n        kernel_initializer = tfk.initializers.GlorotUniform(seed),\n        kernel_regularizer=tf.keras.regularizers.l2(weight_decay)\n    )(pool1)\n    batch_norm2 = tfkl.BatchNormalization()(conv2)\n    pool2 = tfkl.MaxPooling2D(\n        pool_size = (2, 2)\n    )(batch_norm2)\n\n    conv3 = tfkl.Conv2D(\n        filters=64,\n        kernel_size=(3, 3),\n        strides = (1, 1),\n        padding = 'same',\n        activation = 'relu',\n        kernel_initializer = tfk.initializers.GlorotUniform(seed),\n        kernel_regularizer=tf.keras.regularizers.l2(weight_decay)\n    )(pool2)\n    batch_norm3 = tfkl.BatchNormalization()(conv3)\n    pool3 = tfkl.MaxPooling2D(\n        pool_size = (2, 2)\n    )(batch_norm3)\n\n    conv4 = tfkl.Conv2D(\n        filters=128,\n        kernel_size=(3, 3),\n        strides = (1, 1),\n        padding = 'same',\n        activation = 'relu',\n        kernel_initializer = tfk.initializers.GlorotUniform(seed),\n        kernel_regularizer=tf.keras.regularizers.l2(weight_decay)\n    )(pool3)\n    batch_norm4 = tfkl.BatchNormalization()(conv4)\n    pool4 = tfkl.MaxPooling2D(\n        pool_size = (2, 2)\n    )(batch_norm4)\n\n    conv5 = tfkl.Conv2D(\n        filters=256,\n        kernel_size=(3, 3),\n        strides = (1, 1),\n        padding = 'same',\n        activation = 'relu',\n        kernel_initializer = tfk.initializers.GlorotUniform(seed),\n        kernel_regularizer=tf.keras.regularizers.l2(weight_decay)\n    )(pool4)\n    batch_norm5 = tfkl.BatchNormalization()(conv5)\n    globalPool = tfkl.GlobalAveragePooling2D()(batch_norm5)\n\n    flattening_layer = tfkl.Flatten(name='Flatten')(globalPool)\n    flattening_layer = tfkl.Dropout(0.25, seed=seed)(flattening_layer)\n    classifier_layer = tfkl.Dense(units=512, name='Classifier', kernel_initializer=tfk.initializers.GlorotUniform(seed), activation='relu')(flattening_layer)\n    batch_norm6 = tfkl.BatchNormalization()(classifier_layer)\n    classifier_layer = tfkl.Dropout(0.5, seed=seed)(batch_norm6)\n    output_layer = tfkl.Dense(units=n_classes, activation='softmax', kernel_initializer=tfk.initializers.GlorotUniform(seed), name='Output')(classifier_layer)\n\n    # Connect input and output through the Model class\n    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='model')\n\n    # Compile the model\n    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics='accuracy')\n\n    # Return the model\n    return model","metadata":{"id":"DWPOW2KrJLbz","execution":{"iopub.status.busy":"2021-11-16T07:48:18.876307Z","iopub.execute_input":"2021-11-16T07:48:18.876594Z","iopub.status.idle":"2021-11-16T07:48:18.897065Z","shell.execute_reply.started":"2021-11-16T07:48:18.876561Z","shell.execute_reply":"2021-11-16T07:48:18.896371Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Build model\nmodel = build_model(input_shape)\nmodel.summary()","metadata":{"id":"D1wCon5IJtEb","outputId":"fb14c2a9-5345-4826-f838-87b8779a261c","execution":{"iopub.status.busy":"2021-11-16T07:48:26.316208Z","iopub.execute_input":"2021-11-16T07:48:26.316465Z","iopub.status.idle":"2021-11-16T07:48:28.966814Z","shell.execute_reply.started":"2021-11-16T07:48:26.316435Z","shell.execute_reply":"2021-11-16T07:48:28.966119Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"#tfk.utils.plot_model(model)","metadata":{"id":"IQB9t49ZLNvy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training","metadata":{"id":"Ay2OLrM4EhOv"}},{"cell_type":"code","source":"# Utility function to create folders and callbacks for training\nfrom datetime import datetime\n\ndef create_folders_and_callbacks(model_name):\n\n  exps_dir = os.path.join('/kaggle/working/models')\n  if not os.path.exists(exps_dir):\n      os.makedirs(exps_dir)\n\n  now = datetime.now().strftime('%b%d_%H-%M-%S')\n\n  exp_dir = os.path.join(exps_dir, model_name + '_' + str(now))\n  if not os.path.exists(exp_dir):\n      os.makedirs(exp_dir)\n      \n  callbacks = []\n\n  # Model checkpoint\n  # ----------------\n  ckpt_dir = os.path.join(exp_dir, 'ckpts')\n  if not os.path.exists(ckpt_dir):\n      os.makedirs(ckpt_dir)\n\n  ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(ckpt_dir, 'cp.ckpt'), \n                                                     save_weights_only=False, # True to save only weights\n                                                     save_best_only=False) # True to save only the best epoch \n  callbacks.append(ckpt_callback)\n\n  # Visualize Learning on Tensorboard\n  # ---------------------------------\n  #tb_dir = os.path.join(exp_dir, 'tb_logs')\n  #if not os.path.exists(tb_dir):\n  #    os.makedirs(tb_dir)\n      \n  # By default shows losses and metrics for both training and validation\n  #tb_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_dir, \n  #                                             profile_batch=0,\n  #                                             histogram_freq=1)  # if > 0 (epochs) shows weights histograms\n  #callbacks.append(tb_callback)\n\n  # Early Stopping\n  # --------------\n  es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n  callbacks.append(es_callback)\n\n  return callbacks","metadata":{"id":"QZaR4qPFDY53","execution":{"iopub.status.busy":"2021-11-16T07:48:41.736048Z","iopub.execute_input":"2021-11-16T07:48:41.736331Z","iopub.status.idle":"2021-11-16T07:48:41.744896Z","shell.execute_reply.started":"2021-11-16T07:48:41.736300Z","shell.execute_reply":"2021-11-16T07:48:41.744190Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Create folders and callbacks and fit\ncallbacks = create_folders_and_callbacks(model_name=model_name)\n\n# Train the model\nhistory = model.fit(\n    x = train_gen,\n    batch_size = batch_size,\n    epochs = epochs,\n    validation_data = valid_gen,\n    callbacks=[callbacks]\n).history","metadata":{"id":"CHkqrUCXJtkK","outputId":"8f18a74c-efd4-4cfb-bc2e-926ca7e6c175","execution":{"iopub.status.busy":"2021-11-16T07:48:51.219675Z","iopub.execute_input":"2021-11-16T07:48:51.220117Z","iopub.status.idle":"2021-11-16T10:13:51.562577Z","shell.execute_reply.started":"2021-11-16T07:48:51.220083Z","shell.execute_reply":"2021-11-16T10:13:51.561866Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Save best epoch model\nmodel.save(\"/kaggle/working/models/\" + model_name + \"_best_\" + str(datetime.now().strftime('%b%d_%H-%M-%S')))","metadata":{"id":"kMiuNBj3GusE","outputId":"45f3a06d-dcf3-478d-94de-bc065f2ca5d8","execution":{"iopub.status.busy":"2021-11-16T10:16:54.201314Z","iopub.execute_input":"2021-11-16T10:16:54.201799Z","iopub.status.idle":"2021-11-16T10:16:57.933626Z","shell.execute_reply.started":"2021-11-16T10:16:54.201758Z","shell.execute_reply":"2021-11-16T10:16:57.932890Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"### Testing","metadata":{"id":"4Jp8dDwpAxl2"}},{"cell_type":"code","source":"!zip -r /kaggle/working/models_r.zip /kaggle/working/models","metadata":{"execution":{"iopub.status.busy":"2021-11-16T10:21:56.258643Z","iopub.execute_input":"2021-11-16T10:21:56.259412Z","iopub.status.idle":"2021-11-16T10:21:57.570144Z","shell.execute_reply.started":"2021-11-16T10:21:56.259359Z","shell.execute_reply":"2021-11-16T10:21:57.569230Z"},"trusted":true},"execution_count":14,"outputs":[]}]}