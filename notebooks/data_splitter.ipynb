{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "interpreter": {
      "hash": "d5d63078528779411384a0109f22a688b37078cd4f03a8068939f652224ae60f"
    },
    "kernelspec": {
      "display_name": "Python 3.8.8 64-bit ('base': conda)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "Data_Splitter.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsXz12ot7PBB",
        "papermill": {
          "duration": 0.016147,
          "end_time": "2021-11-20T17:49:08.622142",
          "exception": false,
          "start_time": "2021-11-20T17:49:08.605995",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Environment settings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PoKdpXXtab1",
        "papermill": {
          "duration": 0.01613,
          "end_time": "2021-11-20T17:49:08.654787",
          "exception": false,
          "start_time": "2021-11-20T17:49:08.638657",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "### Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVT6JS9FvzwC",
        "papermill": {
          "duration": 5.708461,
          "end_time": "2021-11-20T17:49:14.379517",
          "exception": false,
          "start_time": "2021-11-20T17:49:08.671056",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "source": [
        "import os\n",
        "import random\n",
        "\n",
        "from shutil import copyfile\n",
        "from shutil import move"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4Q-CAiNtnRP",
        "papermill": {
          "duration": 0.016521,
          "end_time": "2021-11-20T17:49:14.414332",
          "exception": false,
          "start_time": "2021-11-20T17:49:14.397811",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "### Random seed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJfQgW-bto8I",
        "papermill": {
          "duration": 0.023548,
          "end_time": "2021-11-20T17:49:14.454695",
          "exception": false,
          "start_time": "2021-11-20T17:49:14.431147",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "source": [
        "# Random seed for reproducibility\n",
        "SEED = 42\n",
        "\n",
        "random.seed(SEED)\n",
        "os.environ['PYTHONHASHSEED'] = str(SEED)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TO49mt3zudRv"
      },
      "source": [
        "# Data Pre-Processing\n",
        "* Training set : 60%\n",
        "* Validation set : 20%\n",
        "* Testing set : 20%\n",
        "\n",
        "**Stratified sampling procedure** : because the proportion among classes are very different and must be preserved in order to avoid biased predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhTFgic4udR5"
      },
      "source": [
        "Parameters setting:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H63Uh8s5udR6"
      },
      "source": [
        "# Directories\n",
        "dataset_dir = 'leaf_dataset' # The name of the original dataset, it has to be in the same directory of this notebook\n",
        "sub_dir_s = ['training','validation','testing']\n",
        "\n",
        "# Splitting proportions\n",
        "train = .6 # 60%\n",
        "val = .2 # 20%\n",
        "test = .2 # 20%\n",
        "\n",
        "# Labels name\n",
        "labels = ['Apple','Blueberry','Cherry','Corn','Grape','Orange','Peach','Pepper','Potato','Raspberry','Soybean','Squash','Strawberry','Tomato']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xda0HUKbudR7"
      },
      "source": [
        "Directories organization:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFIg48-OudR8"
      },
      "source": [
        "# Getting current working directory\n",
        "path = os.getcwd()\n",
        "\n",
        "# Operative directories (training, validation, testing)\n",
        "for sub in sub_dir_s:\n",
        "    # Full path\n",
        "    name = path + '/' + sub\n",
        "\n",
        "    # mkdir\n",
        "    try:\n",
        "        os.mkdir(name)\n",
        "    except OSError:\n",
        "        print (\"Creation of the directory %s failed\" % name)\n",
        "    else:\n",
        "        print (\"Successfully created the directory %s \" % name)   \n",
        "\n",
        "    # For each label (leaf categories)\n",
        "    for label in labels:\n",
        "        # Class directory\n",
        "        class_name = name + '/' + label\n",
        "\n",
        "        # mkdir\n",
        "        try:\n",
        "            os.mkdir(class_name)\n",
        "        except OSError:\n",
        "            print (\"Creation of the directory %s failed\" % class_name)\n",
        "        else:\n",
        "            print (\"Successfully created the directory %s \" % class_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjCRbWZ4udR-"
      },
      "source": [
        "Splitting procedure:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnP3fOrRudR_"
      },
      "source": [
        "# Stratified sampling procedure\n",
        "def stratified_sampling(labels, dataset_path, train_p, val_p):\n",
        "    # params:\n",
        "    # - labels : classes' label to be considered\n",
        "    # - train_p : train samples proportion\n",
        "    # - val_p : validation samples proportion\n",
        "    # - test_p : test samples proportion\n",
        "\n",
        "    # Return lists\n",
        "    train_set = []\n",
        "    val_set = []\n",
        "    test_set = []\n",
        "\n",
        "    # For each class\n",
        "    for i in range(len(labels)):\n",
        "        if i < len(labels):\n",
        "            # Selecting all the images of the i-th class\n",
        "            class_imgs = next(os.walk(os.getcwd() + '/{}/{}/'.format(dataset_path, labels[i])))[2]\n",
        "\n",
        "            # Lenght\n",
        "            class_len = len(class_imgs)\n",
        "\n",
        "            # Shuffling\n",
        "            random.shuffle(class_imgs)\n",
        "\n",
        "            # Splitting\n",
        "            train = class_imgs[:int(train_p*class_len)]\n",
        "            val = class_imgs[int(train_p*class_len):int((train_p + val_p)*class_len)]\n",
        "            test = class_imgs[int((train_p+val_p)*class_len):]\n",
        "\n",
        "            # Append lists to the corresponding index\n",
        "            train_set.append(train)\n",
        "            val_set.append(val)\n",
        "            test_set.append(test)\n",
        "    \n",
        "    return train_set, val_set, test_set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1BP3hxVudSA"
      },
      "source": [
        "Directory populations setting:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzSizyN9udSC"
      },
      "source": [
        "# Stratified sampling\n",
        "train_set, val_set, test_set = stratified_sampling(labels, dataset_dir, train_p=train, val_p=val)\n",
        "\n",
        "# Getting current working directory\n",
        "path = os.getcwd()\n",
        "\n",
        "# Operative directories (training, validation, testing)\n",
        "for sub in sub_dir_s:\n",
        "    # Taking the correct list\n",
        "    if (sub == 'training'):\n",
        "        list = train_set\n",
        "    elif (sub == 'validation'):\n",
        "        list = val_set\n",
        "    else:\n",
        "        list = test_set\n",
        "\n",
        "    # For each class target\n",
        "    for i in labels:\n",
        "        # Source path taking the full dataset from the root\n",
        "        src_path = dataset_dir + '/' + i + '/'\n",
        "\n",
        "        # Destination path taking the target sub directory          \n",
        "        dst_path = path + '/' + sub + '/' + i + '/'\n",
        "\n",
        "        # Copying each image to the new directory\n",
        "        for img in list[labels.index(i)]:\n",
        "            copyfile(src_path + img, dst_path + img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNP9bbvnudSD"
      },
      "source": [
        "Checking numbers:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svXNI6fzudSD"
      },
      "source": [
        "def count_samples_classes(labels, dir_path):\n",
        "    # Counters list\n",
        "    counters = []\n",
        "\n",
        "    # For each class\n",
        "    for i in range(len(labels)):\n",
        "        # Selecting all the images of the i-th class\n",
        "        class_samples = next(os.walk('{}/{}/'.format(dir_path, labels[i])))[2]\n",
        "\n",
        "        # Storing the counter bound with the class target\n",
        "        counters.append((labels[i], len(class_samples)))\n",
        "    \n",
        "    return counters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5l83cColudSD"
      },
      "source": [
        "# Current path\n",
        "path = os.getcwd() + '/'\n",
        "\n",
        "# Original dataset\n",
        "print('Original Dataset:')\n",
        "print(count_samples_classes(labels, path + dataset_dir))\n",
        "\n",
        "# Training set\n",
        "print('\\nTraining set:')\n",
        "print(count_samples_classes(labels, path + 'training'))\n",
        "\n",
        "# Validation set\n",
        "print('\\nValidation set:')\n",
        "print(count_samples_classes(labels, path + 'validation'))\n",
        "\n",
        "# Testing set\n",
        "print('\\nTesting set:')\n",
        "print(count_samples_classes(labels, path + 'testing'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNozhae32Rff"
      },
      "source": [
        "Creating the splitted dataset folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncU-L8nB2NtT"
      },
      "source": [
        "target = 'leaf_dataset_splitted' # Created in the same directory of this notebook\n",
        "if(not os.path.isdir(target)):\n",
        "\tos.mkdir(target)\n",
        "\n",
        "move('training', target + '/training')\n",
        "move('validation', target + '/validation')\n",
        "move('testing', target + '/testing')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}